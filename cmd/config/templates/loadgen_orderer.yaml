orderer-client:
  sidecar-endpoint: {{ .Endpoints.Sidecar }}
  coordinator:
    endpoint: {{ .Endpoints.Coordinator }}
  orderer:
    connection:
      endpoints:
        {{- range .Endpoints.Orderer }}
        - {{ . }}
        {{- end }}
    consensus-type: BFT
    channel-id: {{ .ChannelID }}
  broadcast-parallelism: 50

monitoring:
  server:
    endpoint: {{ .MetricsEndpoint | default "localhost:0" }}
  latency:
    sampler:
      type: hash
      ratio: 10
      sample-size: 100
      sample-period: 100000
    buckets:
      distribution: uniform
      max-latency: 5s
      bucket-count: 1000

load-profile:
  block:
    size: {{ .BlockSize }}
  key:
    size: 32
  transaction:
    read-write-value-size:
    blind-write-value-size:
    read-only-count:
    read-write-count:
      const: 2
    policy:
      namespace-policies:
        {{ range $nsID, $element := .Policy.NamespacePolicies }}
        {{ $nsID }}:
          scheme: {{ $element.Scheme }}
          seed: {{ $element.Seed }}
        {{ end }}
      config-block-path: {{ .ConfigBlockPath }}
  query:
    query-size:
    min-invalid-keys-portion:
    shuffle: false
  conflicts:
    invalid-signatures: 0
    dependencies:
  seed: 12345
  workers: 1

stream:
  rate-limit:
    endpoint: {{ .ServerEndpoint | default "localhost:0" }}
    initial-limit: 1000
  gen-batch: 1
  buffers-size: 1

generate:
  # The sidecar does not support config TX from the stream.
  config: false
  namespaces: true
  load: true

# The stopping condition for generating load according to the collected metrics.
# Zero value indicate no limit.
# The limit on the number of TXs is applied at block granularity. I.e., more TXs might be created than expected
# if a block overshot.
# The load generator stops when both requirements are met, i.e., one of them might overshoot.
# For the orderer adapter, the blocks limit is ignored for broadcasting as we don't track submitted blocks.
# For adapters that use concurrent submitters, we cannot enforce exact limits.
# The sidecar and coordinator adapters are sequential, so they don't have these issues.
limit:
  blocks: {{ .LoadGenBlockLimit }}
  transactions: {{ .LoadGenTXLimit }}

logging:
  enabled: {{ .Logging.Enabled }}
  level: {{ .Logging.Level }}
  caller: {{ .Logging.Caller }}
  development: {{ .Logging.Development }}
  output: {{ .Logging.Output }}
  name: loadgen
